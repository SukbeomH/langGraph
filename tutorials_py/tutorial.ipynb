{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatAnthropic\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# .env 파일에서 환경 변수 로드\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 기본적인 LLM 모델 설정\n",
    "\n",
    "ChatAnthropic 사용 가능 모델\n",
    "현재 ChatAnthropic을 통해 사용할 수 있는 주요 모델들은 다음과 같습니다:\n",
    "\n",
    "```python\n",
    "# 사용 가능한 Anthropic Claude 모델들\n",
    "models = {\n",
    "    \"claude-3-opus-20240229\": \"최신 Claude 3 Opus 모델\",\n",
    "    \"claude-3-sonnet-20240229\": \"최신 Claude 3 Sonnet 모델\", \n",
    "    \"claude-2.1\": \"Claude 2.1 모델\",\n",
    "    \"claude-2.0\": \"Claude 2.0 모델\",\n",
    "    \"claude-instant-1.2\": \"Claude Instant 1.2 모델\"\n",
    "}\n",
    "```\n",
    "\n",
    "## Claude-3 Opus와 Sonnet의 주요 차이점\n",
    "\n",
    "### 1. 성능 차이\n",
    "\n",
    "- Opus\n",
    "  - Claude-3 제품군의 최고 성능 모델\n",
    "  - 가장 복잡하고 정교한 작업 수행 가능\n",
    "  - 더 긴 컨텍스트와 정확한 분석 제공\n",
    "\n",
    "- Sonnet\n",
    "  - 중간 수준의 성능 모델\n",
    "  - 일반적인 작업에 적합\n",
    "  - 비용 효율적인 선택\n",
    "\n",
    "### 2. 토큰 처리\n",
    "\n",
    "- Opus: 최대 200K 토큰 처리 가능\n",
    "- Sonnet: 최대 200K 토큰 처리 가능\n",
    "\n",
    "### 3. 가격 (1K 토큰 기준)\n",
    "\n",
    "- Opus\n",
    "  - Input: $0.015\n",
    "  - Output: $0.075\n",
    "\n",
    "- Sonnet\n",
    "  - Input: $0.003\n",
    "  - Output: $0.015\n",
    "\n",
    "\n",
    "### 4. 사용 추천\n",
    "\n",
    "- Opus 추천 용도\n",
    "  - 복잡한 분석이 필요한 작업\n",
    "  - 고난도 코딩 작업\n",
    "  - 정확도가 매우 중요한 작업\n",
    "\n",
    "- Sonnet 추천 용도\n",
    "  - 일반적인 대화형 응답\n",
    "  - 기본적인 코딩 작업\n",
    "  - 비용 효율적인 운영이 필요한 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude-3 Sonnet 설정 (비용 효율적인 옵션)\n",
    "claude_compact = ChatAnthropic(\n",
    "    model_name=\"claude-3-sonnet-20240229\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=150,\n",
    ")\n",
    "\n",
    "# Claude-3 Opus 설정 (최고 성능 옵션)\n",
    "claude = ChatAnthropic(\n",
    "    model_name=\"claude-3-opus-20240229\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=300,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# claude-3-sonnet 사용\n",
    "response_compact = claude_compact.invoke([HumanMessage(content=\"Hello, how are you?\")])\n",
    "print(response_compact.content)\n",
    "\n",
    "# claude-3-opus 사용\n",
    "response_full = claude.invoke(\n",
    "    [HumanMessage(content=\"Explain the concept of machine learning.\")]\n",
    ")\n",
    "print(response_full.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
